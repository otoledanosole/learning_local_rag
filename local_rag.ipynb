{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/otoledanosole/learning_local_rag/blob/main/local_rag.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creation of a Local Retrieval Augmented Genration (RAG)\n",
        "\n",
        "Objective of the document"
      ],
      "metadata": {
        "id": "SrcJEbIGn99m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example of what we are triying to build\n",
        "\n",
        "<img src=\"https://github.com/otoledanosole/learning_local_rag/blob/main/images/Nvidia_rag-pipeline-ingest-query-flow-b-2048x960.png?raw=true\" alt=\"Retrieval Augmented Generation (RAG) Sequence Diagram from Nvidia\" />\n",
        "\n",
        "We are going to use the post [\"RAG 101: Demystifying Retrieval Augmented Generation Pipelines\"](https://developer.nvidia.com/blog/rag-101-demystifying-retrieval-augmented-generation-pipelines/) from the Nvidia Technical Blog as a reference of what we are going to build except that we are not going to use an exsistant framework.\n",
        "\n",
        "The objective is, instead of using LangChain or LlamaIndex as they do in the example, we are going to build our own framework in order to really understand what a RAG is.\n"
      ],
      "metadata": {
        "id": "jFesvf_IojUG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What is RAG?\n",
        "\n",
        "RAG stands for Retrieval Augmented Generation\n",
        "\n",
        "RAG is a technique for enhancing the acuracy and reliability of generative AI models with facts fetched from external resources.\n",
        "\n",
        "It was firstly introduced in a 202 paper called: [Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks](https://arxiv.org/abs/2005.11401#)\n",
        "\n",
        "To understand it with a real example, imagine a psycologist:\n",
        ">A psycologist can create strategies or aply treatment to their patients based of their general understanding of diferent psycology techniques but sometimes a patient requires special expertise so psycologist send clerks to a library where they store specific studies they can use\n",
        "\n",
        "Like a good psycologyst, large language models (LLMs) can respond to a variety of queries  but if we look under de hood of a LLM we find a neural network with parametres that essentialy represent the general patterns of how humans use words to form sentences. Some pre-trained LLMs models have been shown to store factual knowledge in their parameters, working as a parameterized implicit knowledge base.\n",
        "\n",
        "While this is interesting, such models have downsides: the information that they are based of is dificult to update o revise, they may cause \"hallucinations\" and they can not provide in depth knowledge of a specific topic. Some hybrid models combine parametric and non-parametric memories.\n",
        "\n",
        "The goal of RAG is to take information from a source, pre-process it and pass it to an LLM so it can generate outputs based on that information.\n",
        "\n",
        "\n",
        ">To understand what retrieval-augmented generation means, we can roughly broke down eatch step to:\n",
        "* Retrieval - Find relevant information given a query, also known as prompt. For example: \"What pushes a person to act against his beliefs?\" â†’ retrieves the information related to this topic from a given sorurce, for example the book \"Social psycology\" from Solomon Asch.\n",
        "* Augmented - Take the relevant information and augment our input to an LLM with that relevant information.\n",
        "* Generation - Take the firsts two steps and pass them to an LLM for generative outputs.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2XrtqOcXZlbh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sources\n",
        "\n",
        "https://arxiv.org/abs/2005.11401#\n",
        "\n",
        "https://blogs.nvidia.com/blog/what-is-retrieval-augmented-generation/"
      ],
      "metadata": {
        "id": "tdmF69mMeBwK"
      }
    }
  ],
  "metadata": {
    "colab": {
      "name": "Te damos la bienvenida a Colaboratory",
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}